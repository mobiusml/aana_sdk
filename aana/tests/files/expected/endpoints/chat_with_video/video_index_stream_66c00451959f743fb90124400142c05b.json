[
    {
        "data": {},
        "error": "RuntimeError",
        "message": "CUDA failed with error out of memory",
        "stacktrace": "\u001b[36mray::py:WhisperDeployment.handle_request_streaming()\u001b[39m (pid=2231386, ip=172.17.0.5, actor_id=c3e013a416967f2880b5161c01000000, repr=<ray.serve._private.replica.ServeReplica:aana_tests_integration_test_chat_with_video.py:WhisperDeployment object at 0x7fc9a924f790>)\n    async for result in generator:\n  File \"/root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 896, in call_user_method_generator\n    async for result in result_generator:\n  File \"/workspaces/aana_sdk/aana/utils/test.py\", line 144, in wrapper_generator\n    async for item in func(*args, **kwargs):\n  File \"/workspaces/aana_sdk/aana/deployments/whisper_deployment.py\", line 213, in transcribe_stream\n    for segment in segments:\n  File \"/root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/faster_whisper/transcribe.py\", line 1521, in restore_speech_timestamps\n    for segment in segments:\n  File \"/root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/faster_whisper/transcribe.py\", line 725, in generate_segments\n    ) = self.generate_with_fallback(encoder_output, prompt, tokenizer, options)\n  File \"/root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/faster_whisper/transcribe.py\", line 938, in generate_with_fallback\n    result = self.model.generate(\nRuntimeError: CUDA failed with error out of memory"
    }
]