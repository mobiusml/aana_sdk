{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aana.api.sdk import AanaSDK\n",
    "from aana.api.sdk import get_deployment\n",
    "\n",
    "\n",
    "aana_sdk = AanaSDK(port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aana.deployments.whisper_deployment import (\n",
    "    WhisperComputeType,\n",
    "    WhisperConfig,\n",
    "    WhisperDeployment,\n",
    "    WhisperModelSize,\n",
    ")\n",
    "\n",
    "whisper_deployment_medium = WhisperDeployment.options(\n",
    "    num_replicas=1,\n",
    "    max_concurrent_queries=1000,\n",
    "    ray_actor_options={\"num_gpus\": 0.25},\n",
    "    user_config=WhisperConfig(\n",
    "        model_size=WhisperModelSize.MEDIUM,\n",
    "        compute_type=WhisperComputeType.FLOAT16,\n",
    "    ).model_dump(),\n",
    ")\n",
    "\n",
    "aana_sdk.register_deployment(\n",
    "    \"whisper_deployment_medium\",\n",
    "    whisper_deployment_medium,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aana.deployments.hf_blip2_deployment import HFBlip2Config, HFBlip2Deployment\n",
    "from aana.models.core.dtype import Dtype\n",
    "\n",
    "blip2_deployment = HFBlip2Deployment.options(\n",
    "    num_replicas=1,\n",
    "    max_concurrent_queries=1000,\n",
    "    ray_actor_options={\"num_gpus\": 0.25},\n",
    "    user_config=HFBlip2Config(\n",
    "        model=\"Salesforce/blip2-opt-2.7b\",\n",
    "        dtype=Dtype.FLOAT16,\n",
    "        batch_size=2,\n",
    "        num_processing_threads=2,\n",
    "    ).model_dump(),\n",
    ")\n",
    "\n",
    "aana_sdk.register_deployment(\n",
    "    \"blip2_deployment\",\n",
    "    blip2_deployment,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aana.deployments.vllm_deployment import VLLMConfig, VLLMDeployment\n",
    "from aana.models.pydantic.sampling_params import SamplingParams\n",
    "\n",
    "\n",
    "vllm_llama2_7b_chat_deployment = VLLMDeployment.options(\n",
    "    num_replicas=1,\n",
    "    max_concurrent_queries=1000,\n",
    "    ray_actor_options={\"num_gpus\": 0.25},\n",
    "    user_config=VLLMConfig(\n",
    "        model=\"TheBloke/Llama-2-7b-Chat-AWQ\",\n",
    "        dtype=\"auto\",\n",
    "        quantization=\"awq\",\n",
    "        gpu_memory_reserved=13000,\n",
    "        enforce_eager=True,\n",
    "        default_sampling_params=SamplingParams(\n",
    "            temperature=0.0, top_p=1.0, top_k=-1, max_tokens=1024\n",
    "        ),\n",
    "        chat_template=\"llama2\",\n",
    "    ).model_dump(),\n",
    ")\n",
    "\n",
    "aana_sdk.register_deployment(\n",
    "    \"vllm_llama2_7b_chat_deployment\",\n",
    "    vllm_llama2_7b_chat_deployment,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aana.models.pydantic.video_input import VideoInput\n",
    "from aana.utils.video import download_video, extract_audio\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=UQuIVsNzqDk\"\n",
    "video_input = VideoInput(url=url)\n",
    "\n",
    "video = download_video(video_input=video_input)\n",
    "audio = extract_audio(video=video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aana.models.pydantic.whisper_params import WhisperParams\n",
    "\n",
    "whisper_params = WhisperParams()\n",
    "\n",
    "whisper_output = await get_deployment(\"whisper_deployment_medium\").transcribe.remote(\n",
    "    audio=audio, params=whisper_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aana.models.pydantic.video_params import VideoParams\n",
    "from aana.utils.video import generate_frames_decord\n",
    "\n",
    "video_params = VideoParams()\n",
    "\n",
    "timestamps = []\n",
    "frame_ids = []\n",
    "captions = []\n",
    "\n",
    "for frames_dict in generate_frames_decord(\n",
    "    video=video, params=video_params, batch_size=4\n",
    "):\n",
    "    captions_dict = await get_deployment(\"blip2_deployment\").generate_batch.remote(\n",
    "        images=frames_dict[\"frames\"]\n",
    "    )\n",
    "\n",
    "    timestamps.extend(frames_dict[\"timestamps\"])\n",
    "    frame_ids.extend(frames_dict[\"frame_ids\"])\n",
    "    captions.extend(captions_dict[\"captions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aana.utils.video import generate_combined_timeline\n",
    "\n",
    "timeline_dict = generate_combined_timeline(\n",
    "    transcription_segments=whisper_output[\"segments\"],\n",
    "    captions=captions,\n",
    "    caption_timestamps=timestamps,\n",
    ")\n",
    "timeline = timeline_dict[\"timeline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline_sentences = [\n",
    "    f\"{segment['audio_transcript']}\\n{segment['visual_caption']}\"\n",
    "    for segment in timeline\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline_embeddings_dict = await get_deployment(\n",
    "    \"mxbai_embed_large_v1_deployment\"\n",
    ").embed_batch.remote(sentences=timeline_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline_embeddings_dict[\"embedding\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_integrations.document_stores.qdrant import QdrantDocumentStore\n",
    "\n",
    "document_store = QdrantDocumentStore(\n",
    "    path=\"/tmp/qdrant_index\",\n",
    "    recreate_index=True,\n",
    "    embedding_dim=1024,\n",
    "    return_embedding=True,\n",
    "    wait_result_from_api=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "\n",
    "doc_writer = DocumentWriter(\n",
    "    document_store=document_store, policy=DuplicatePolicy.OVERWRITE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Document\n",
    "\n",
    "\n",
    "timeline_docs = [\n",
    "    Document(content=sentence, embedding=embedding)\n",
    "    for sentence, embedding in zip(\n",
    "        timeline_sentences, timeline_embeddings_dict[\"embedding\"]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(timeline_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.write_documents(timeline_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Why green screen is not a perfect solution?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding_dict = await get_deployment(\n",
    "    \"mxbai_embed_large_v1_deployment\"\n",
    ").embed_batch.remote(sentences=[query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = document_store.query_by_embedding(\n",
    "    query_embedding_dict[\"embedding\"][0].tolist(), top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding_dict[\"embedding\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "template = \"\"\"\n",
    "<s>[INST] Given the following information, answer the question factually from the content you have.\n",
    "\n",
    "If there is no information in the collection, say that and politely refuse to answer the question.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_dict = prompt_builder.run(documents=retrieved_docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams()\n",
    "\n",
    "answer = await get_deployment(\"vllm_llama2_7b_chat_deployment\").generate.remote(\n",
    "    prompt=prompt_dict[\"prompt\"], sampling_params=sampling_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedder = SentenceTransformersDocumentEmbedder(\n",
    "    model=\"mixedbread-ai/mxbai-embed-large-v1\", meta_fields_to_embed=[\"summary\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedder.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = doc_embedder.run(documents=[Document(content=\"Hello, World!\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(docs[\"documents\"][0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedder_with_deployment = SentenceTransformersDeploymentEmbedder(\n",
    "    \"mxbai_embed_large_v1_deployment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedder_with_deployment.arun(documents=[Document(content=\"Hello, World!\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "data = {\"video_input\": {\"url\": \"https://www.youtube.com/watch?v=UQuIVsNzqDk\"}}\n",
    "# data = {\"video_input\": {\"url\": \"https://www.youtube.com/watch?v=33BZfufw8cI\"}}\n",
    "response = requests.post(\n",
    "    \"http://127.0.0.1:8000/index_video\",\n",
    "    data={\"body\": json.dumps(data)},\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in response.iter_content(chunk_size=None):\n",
    "    print(json.loads(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "data = {\"query\": \"What is an alternative to green screen?\"}\n",
    "# data = {\"query\": \"Why green screen is not a perfect solution?\"}\n",
    "response = requests.post(\n",
    "    \"http://127.0.0.1:8000/chat\",\n",
    "    data={\"body\": json.dumps(data)},\n",
    "    stream=True,\n",
    ")\n",
    "text = \"\"\n",
    "for chunk in response.iter_content(chunk_size=None):\n",
    "    text = text + json.loads(chunk)[\"text\"]\n",
    "    print(json.loads(chunk)[\"text\"], end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aana-XDlPP_xZ-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
