{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Identification Example\n",
    "\n",
    "The notebook shows how to use face recognition with Aana SDK. Face recognition uses three separate deployments:\n",
    "1. **Face Detection**, which returns bounding boxes and face landmarks (keypoints) for each detected face\n",
    "2. **Face Feature Extraction**, which for a given image and face landmarks returns a face feature that can be used to compare face similarities.\n",
    "3. **Face Database**, which uses 1 and 2 to extract reference faces and populate a reference face database that can be used to search for known identities across image/video collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n",
      "Requirement already satisfied: onnxruntime-gpu in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (1.18.1)\n",
      "Requirement already satisfied: coloredlogs in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from onnxruntime-gpu) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from onnxruntime-gpu) (24.3.25)\n",
      "Requirement already satisfied: numpy<2.0,>=1.21.6 in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from onnxruntime-gpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from onnxruntime-gpu) (24.0)\n",
      "Requirement already satisfied: protobuf in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from onnxruntime-gpu) (5.26.1)\n",
      "Requirement already satisfied: sympy in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from onnxruntime-gpu) (1.12)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# For onnx GPU support (face detection model), execute this code\n",
    "!pip install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the face detection deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-17 06:51:03,500\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_dir\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
      "  warnings.warn(\n",
      "2024-07-17 06:51:07,593\tWARNING services.py:2009 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-07-17 06:51:08,787\tINFO worker.py:1740 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "The new client HTTP config differs from the existing one in the following fields: ['location']. The new HTTP config is ignored.\n",
      "2024-07-17 06:51:13,152\tINFO handle.py:126 -- Created DeploymentHandle 'aoqnprn7' for Deployment(name='FaceDetectorDeployment', app='face_detector').\n",
      "2024-07-17 06:51:13,154\tINFO handle.py:126 -- Created DeploymentHandle 'j3ir7vwr' for Deployment(name='FaceDetectorDeployment', app='face_detector').\n",
      "2024-07-17 06:51:16,197\tINFO handle.py:126 -- Created DeploymentHandle '2p1xpces' for Deployment(name='FaceDetectorDeployment', app='face_detector').\n",
      "2024-07-17 06:51:16,199\tINFO api.py:584 -- Deployed app 'face_detector' successfully.\n",
      "2024-07-17 06:51:16,212\tINFO handle.py:126 -- Created DeploymentHandle 'h271bym2' for Deployment(name='FaceDetectorDeployment', app='face_detector').\n",
      "2024-07-17 06:51:16,227\tINFO pow_2_scheduler.py:260 -- Got updated replicas for Deployment(name='FaceDetectorDeployment', app='face_detector'): {'dhx23e3s'}.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from aana.deployments.aana_deployment_handle import AanaDeploymentHandle\n",
    "from aana.deployments.face_detection_deployment import (\n",
    "    FaceDetectorConfig,\n",
    "    FaceDetectorDeployment,\n",
    ")\n",
    "\n",
    "from aana.sdk import AanaSDK\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "aana_app = AanaSDK()\n",
    "aana_app.connect(show_logs=False)\n",
    "\n",
    "# Instantiate and register the face detection deployment\n",
    "face_detector_deployment = FaceDetectorDeployment.options(\n",
    "    num_replicas=1,\n",
    "    ray_actor_options={\"num_gpus\": 0.1},\n",
    "    user_config=FaceDetectorConfig(\n",
    "        nms_thresh=0.4,\n",
    "        batch_size=4,\n",
    "        input_size=640,\n",
    "    ).model_dump(mode=\"json\"),\n",
    ")\n",
    "\n",
    "aana_app.register_deployment(\"face_detector\", face_detector_deployment, deploy=True)\n",
    "facedetector_handle = await AanaDeploymentHandle.create(\"face_detector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the face feature extraction deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new client HTTP config differs from the existing one in the following fields: ['location']. The new HTTP config is ignored.\n",
      "2024-07-17 06:51:21,542\tINFO handle.py:126 -- Created DeploymentHandle 'mm6lgbwf' for Deployment(name='FacefeatureExtractorDeployment', app='facefeat_extractor').\n",
      "2024-07-17 06:51:21,544\tINFO handle.py:126 -- Created DeploymentHandle '4cqnmqrh' for Deployment(name='FacefeatureExtractorDeployment', app='facefeat_extractor').\n",
      "2024-07-17 06:51:28,616\tINFO handle.py:126 -- Created DeploymentHandle 'oq4hqr9v' for Deployment(name='FacefeatureExtractorDeployment', app='facefeat_extractor').\n",
      "2024-07-17 06:51:28,618\tINFO api.py:584 -- Deployed app 'facefeat_extractor' successfully.\n",
      "2024-07-17 06:51:28,630\tINFO handle.py:126 -- Created DeploymentHandle 'ogn9hdzs' for Deployment(name='FacefeatureExtractorDeployment', app='facefeat_extractor').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 06:51:28,645\tINFO pow_2_scheduler.py:260 -- Got updated replicas for Deployment(name='FacefeatureExtractorDeployment', app='facefeat_extractor'): {'9m26ia5j'}.\n",
      "2024-07-17 06:51:38,277\tINFO pow_2_scheduler.py:260 -- Got updated replicas for Deployment(name='FaceDatabaseDeployment', app='face_database'): {'ftlj9gfc'}.\n"
     ]
    }
   ],
   "source": [
    "from aana.deployments.face_featureextraction_deployment import (\n",
    "    FacefeatureExtractorConfig,\n",
    "    FacefeatureExtractorDeployment,\n",
    ")\n",
    "\n",
    "FACEFEATURE_MODEL = \"ir_101_webface4M\"  # Name of the face feature model to be used. This has to be the same one for face feature extraction deployment and reference face database.\n",
    "\n",
    "# Instantiate and register the face feature extraction deployment\n",
    "facefeat_extractor_deployment = FacefeatureExtractorDeployment.options(\n",
    "    num_replicas=1,\n",
    "    ray_actor_options={\"num_gpus\": 0.2},\n",
    "    user_config=FacefeatureExtractorConfig(\n",
    "        feature_extractor_name=FACEFEATURE_MODEL,\n",
    "        min_face_norm=19.0,\n",
    "    ).model_dump(mode=\"json\"),\n",
    ")\n",
    "\n",
    "aana_app.register_deployment(\n",
    "    \"facefeat_extractor\", facefeat_extractor_deployment, deploy=True\n",
    ")\n",
    "facefeat_handle = await AanaDeploymentHandle.create(\"facefeat_extractor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the reference face database deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new client HTTP config differs from the existing one in the following fields: ['location']. The new HTTP config is ignored.\n",
      "2024-07-17 06:51:31,182\tINFO handle.py:126 -- Created DeploymentHandle 'tnzpda8t' for Deployment(name='FaceDatabaseDeployment', app='face_database').\n",
      "2024-07-17 06:51:31,184\tINFO handle.py:126 -- Created DeploymentHandle 'p3fwj0u2' for Deployment(name='FaceDatabaseDeployment', app='face_database').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 06:51:38,252\tINFO handle.py:126 -- Created DeploymentHandle '3ea7ghc7' for Deployment(name='FaceDatabaseDeployment', app='face_database').\n",
      "2024-07-17 06:51:38,254\tINFO api.py:584 -- Deployed app 'face_database' successfully.\n",
      "2024-07-17 06:51:38,265\tINFO handle.py:126 -- Created DeploymentHandle 'p259lxjg' for Deployment(name='FaceDatabaseDeployment', app='face_database').\n"
     ]
    }
   ],
   "source": [
    "from aana.deployments.face_database_deployment import (\n",
    "    FaceDatabaseConfig,\n",
    "    FaceDatabaseDeployment,\n",
    ")\n",
    "from aana.configs.settings import settings\n",
    "\n",
    "face_database_deployment = FaceDatabaseDeployment.options(\n",
    "    num_replicas=1,\n",
    "    ray_actor_options={\"num_gpus\": 0.1},\n",
    "    user_config=FaceDatabaseConfig(\n",
    "        face_threshold=1.18,\n",
    "        face_features_directory=settings.artifacts_dir / \"face_features_database\",\n",
    "        feature_extractor_name=FACEFEATURE_MODEL,\n",
    "    ).model_dump(mode=\"json\"),\n",
    ")\n",
    "\n",
    "aana_app.register_deployment(\"face_database\", face_database_deployment, deploy=True)\n",
    "\n",
    "facedatabase_handle = await AanaDeploymentHandle.create(\"face_database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 06:51:41,334\tINFO handle.py:126 -- Created DeploymentHandle '29qqxp9n' for Deployment(name='FaceDetectorDeployment', app='face_detector').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounding_boxes': [array([[415.59457   ,  96.23158   , 481.6673    , 184.54308   ,\n",
      "          0.87722456],\n",
      "       [188.31061   ,  60.958458  , 272.11404   , 174.89207   ,\n",
      "          0.7909324 ]], dtype=float32)], 'keypoints': [array([[[443.3935 , 131.3212 ],\n",
      "        [471.51398, 133.13217],\n",
      "        [462.67175, 147.79501],\n",
      "        [447.37967, 164.56483],\n",
      "        [467.67795, 165.76624]],\n",
      "\n",
      "       [[232.06563, 103.42656],\n",
      "        [264.94907, 106.04597],\n",
      "        [261.4791 , 123.83058],\n",
      "        [233.09895, 144.04256],\n",
      "        [261.0374 , 146.01912]]], dtype=float32)]}\n"
     ]
    }
   ],
   "source": [
    "from aana.core.models.image import Image\n",
    "from pathlib import Path\n",
    "\n",
    "image = Image(\n",
    "    path=Path(\n",
    "        \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000101.jpg\"\n",
    "    )\n",
    ")\n",
    "\n",
    "detector_output = await facedetector_handle.predict([image])\n",
    "\n",
    "print(detector_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Face feature extraction using the output of the face detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 06:51:46,511\tINFO handle.py:126 -- Created DeploymentHandle 'b05r8988' for Deployment(name='FacefeatureExtractorDeployment', app='facefeat_extractor').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'facefeats_per_image': [{'face_feats': array([[-0.04401124, -0.0272526 ,  0.01495183, ..., -0.06465618,\n",
      "         0.0389987 ,  0.0128512 ],\n",
      "       [ 0.01096947, -0.02446904,  0.03266014, ..., -0.01851118,\n",
      "         0.01181385,  0.02578571]], dtype=float32), 'norms': array([[21.607306],\n",
      "       [23.78863 ]], dtype=float32)}]}\n"
     ]
    }
   ],
   "source": [
    "keypoints = detector_output[\"keypoints\"]\n",
    "facefeat_output = await facefeat_handle.predict([image], keypoints)\n",
    "\n",
    "print(facefeat_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search the reference face database with the face features we extracted above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 06:51:50,171\tINFO handle.py:126 -- Created DeploymentHandle '5glsy2hd' for Deployment(name='FaceDatabaseDeployment', app='face_database').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32898 identities in the reference face database.\n",
      "The first 10 are: ['Paola Minaccioni', 'Yann Hnautra', 'Anna Raadsveld', 'Charlotte Arnold', 'Dustin Clare', 'Erica Carroll', 'J.A. Bayona', 'Kathryn Bigelow', 'Yon González', 'Gil Darnell']\n"
     ]
    }
   ],
   "source": [
    "all_identities_in_database = await facedatabase_handle.get_all_identities()\n",
    "\n",
    "print(\n",
    "    \"There are {} identities in the reference face database.\".format(\n",
    "        len(all_identities_in_database)\n",
    "    )\n",
    ")\n",
    "print(\"The first 10 are: {}\".format(all_identities_in_database[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 06:52:08,475\tINFO handle.py:126 -- Created DeploymentHandle 'wmb2bj6e' for Deployment(name='FaceDatabaseDeployment', app='face_database').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identities': [{'person_id': 'Donna Murphy', 'image_id': '587eed19-0fd7-4f1b-8911-e347f86b1bc8', 'distance': 0.7868431806564331}, {'person_id': 'Patrick Stewart', 'image_id': '00a35c5b-aacf-4574-8219-9c4cb36486a4', 'distance': 0.7150369882583618}]}\n"
     ]
    }
   ],
   "source": [
    "recognized_faces = await facedatabase_handle.search(\n",
    "    facefeat_output[\"facefeats_per_image\"][0][\"face_feats\"]\n",
    ")\n",
    "print(recognized_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUG (Ignore anything below here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aana.configs.settings import settings\n",
    "import importlib\n",
    "import aana.deployments.face_database_deployment\n",
    "\n",
    "importlib.reload(aana.deployments.face_database_deployment)\n",
    "from aana.deployments.face_database_deployment import (\n",
    "    FaceDatabaseConfig,\n",
    "    FaceDatabaseDeployment,\n",
    ")\n",
    "\n",
    "\n",
    "facedatabase_config = FaceDatabaseConfig(\n",
    "    face_threshold=1.18,\n",
    "    face_features_directory=settings.artifacts_dir / \"face_features_database\",\n",
    "    feature_extractor_name=FACEFEATURE_MODEL,\n",
    ")\n",
    "facedatabase_deployment = FaceDatabaseDeployment()\n",
    "await facedatabase_deployment.apply_config(facedatabase_config.model_dump(mode=\"json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "facefeats_ir101_web4M = np.load(\n",
    "    \"/nas/dominic/AanaFaceEval/reference_facedict_aanasdk_webface4M_r101.npy\",\n",
    "    allow_pickle=True,\n",
    ").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32898 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'facedatabase_deployment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m name_ \u001b[38;5;241m=\u001b[39m facefeats_ir101_web4M[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperson_names\u001b[39m\u001b[38;5;124m\"\u001b[39m][k]\n\u001b[1;32m      6\u001b[0m img_id \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      7\u001b[0m     facefeats_ir101_web4M[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaths_to_image\u001b[39m\u001b[38;5;124m\"\u001b[39m][k]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|||\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      8\u001b[0m )  \u001b[38;5;66;03m# eg '000744f4-4131-44db-a569-ca211fa55a48'\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m facedatabase_deployment\u001b[38;5;241m.\u001b[39madd_reference_face(\n\u001b[1;32m     11\u001b[0m     ffeat, person_name\u001b[38;5;241m=\u001b[39mname_, image_id\u001b[38;5;241m=\u001b[39mimg_id\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'facedatabase_deployment' is not defined"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "for k in tqdm.tqdm(range(len(facefeats_ir101_web4M[\"face_features\"]))):\n",
    "    ffeat = facefeats_ir101_web4M[\"face_features\"][k]\n",
    "    name_ = facefeats_ir101_web4M[\"person_names\"][k]\n",
    "    img_id = (\n",
    "        facefeats_ir101_web4M[\"paths_to_image\"][k].split(\"|||\")[0].split(\"/\")[-1]\n",
    "    )  # eg '000744f4-4131-44db-a569-ca211fa55a48'\n",
    "\n",
    "    res = await facedatabase_handle.add_reference_face(\n",
    "        ffeat, person_name=name_, image_id=img_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': [{'path': 'image1.jpg'}, {'path': 'image2.jpg'}, {'path': 'image3.jpg'}, {'path': 'image4.jpg'}, {'path': 'image5.jpg'}, {'path': 'image6.jpg'}, {'path': 'image7.jpg'}, {'path': 'image8.jpg'}, {'path': 'image9.jpg'}, {'path': 'image10.jpg'}]}\n"
     ]
    }
   ],
   "source": [
    "# Sample image paths\n",
    "image_paths = [\n",
    "    \"image1.jpg\",\n",
    "    \"image2.jpg\",\n",
    "    \"image3.jpg\",\n",
    "    \"image4.jpg\",\n",
    "    \"image5.jpg\",\n",
    "    \"image6.jpg\",\n",
    "    \"image7.jpg\",\n",
    "    \"image8.jpg\",\n",
    "    \"image9.jpg\",\n",
    "    \"image10.jpg\",\n",
    "]\n",
    "\n",
    "# Populate the data dictionary\n",
    "data = {\"images\": [{\"path\": im_path} for im_path in image_paths[0:10]]}\n",
    "\n",
    "# Print the result\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "\n",
    "def extract_face_feats(im_path):\n",
    "    data = {\n",
    "        \"images\": [{\"path\": im_path}, {\"path\": im_path}],\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        \"http://127.0.0.1:8000/recognize_faces\",\n",
    "        data={\"body\": json.dumps(data)},\n",
    "        stream=False,\n",
    "    )\n",
    "    res = response.json()\n",
    "\n",
    "    return res\n",
    "    # return res['face_features_per_image'][0]['face_feats'], res['face_features_per_image'][0]['norms']\n",
    "\n",
    "\n",
    "def extract_face_feats_batched(im_paths):\n",
    "    data = {\"images\": [{\"path\": im_path} for im_path in im_paths]}\n",
    "\n",
    "    print(data)\n",
    "\n",
    "    response = requests.post(\n",
    "        \"http://127.0.0.1:8000/recognize_faces\",\n",
    "        data={\"body\": json.dumps(data)},\n",
    "        stream=False,\n",
    "    )\n",
    "    res = response.json()\n",
    "\n",
    "    return res\n",
    "\n",
    "    # face_feats = [res['face_features_per_image'][k]['face_feats'] for k in range(len(res['face_features_per_image']))]\n",
    "    # norms = [res['face_features_per_image'][k]['norms'] for k in range(len(res['face_features_per_image']))]\n",
    "\n",
    "    # return face_feats, norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = extract_face_feats(\n",
    "    \"/nas/dominic/AanaFaceEval/identities_reference/default/000bb305-88c1-4490-977f-59e66b755cd4|||Ilse Neubauer.jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': [{'path': '/nas/dominic/AanaFaceEval/identities_reference/default/000744f4-4131-44db-a569-ca211fa55a48|||Keita Machida.jpg'}, {'path': '/nas/dominic/AanaFaceEval/identities_reference/default/0007970d-a5d9-4791-bb47-9c52d4cf4473|||Caroleen Feeney.jpg'}, {'path': '/nas/dominic/AanaFaceEval/identities_reference/default/0009aaba-e0da-46c3-a557-72d318ce0bd8|||Ewa Fröling.jpg'}, {'path': '/nas/dominic/AanaFaceEval/identities_reference/default/000b66a3-5009-4513-aa13-535202c679b3|||Marielle Heller.jpg'}, {'path': '/nas/dominic/AanaFaceEval/identities_reference/default/000bb305-88c1-4490-977f-59e66b755cd4|||Ilse Neubauer.jpg'}, {'path': '/nas/dominic/AanaFaceEval/identities_reference/default/000d385b-ac12-41b0-9692-7abff6c5546a|||Michel Joelsas.jpg'}, {'path': '/nas/dominic/AanaFaceEval/identities_reference/default/00112729-6837-424c-bdf5-1709b9b38cba|||Patricia Hodge.jpg'}, {'path': '/nas/dominic/AanaFaceEval/identities_reference/default/00115272-41a7-4b22-bb5a-ea079aa2dea6|||Gillian Anderson.jpg'}, {'path': '/nas/dominic/AanaFaceEval/identities_reference/default/00120863-71aa-4489-83cb-2e90b736ca09|||Apoorva Gowda.jpg'}, {'path': '/nas/dominic/AanaFaceEval/identities_reference/default/0014b61b-1743-4f4d-a8a3-d23844c050c8|||Rebecca Pidgeon.jpg'}]}\n"
     ]
    }
   ],
   "source": [
    "data = {\"images\": [{\"path\": im_path} for im_path in image_paths[0:10]]}\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': [{'path': '/nas/dominic/AanaFaceEval/identities_reference/default/001c3bcf-3ab0-48cc-b805-c8da6ed3ba6a|||Eryk Lubos.jpg'}, {'path': '/nas/dominic/AanaFaceEval/identities_reference/default/001d0484-4b83-42da-bff9-145bcc46359b|||Sanjjanaa Archana Galrani.jpg'}, {'path': '/nas/dominic/AanaFaceEval/identities_reference/default/001e04f1-a8f4-45e0-a85d-59d8bf06f12a|||Gerald Okamura.jpg'}, {'path': '/nas/dominic/AanaFaceEval/identities_reference/default/0021297f-e5f7-4965-a0cd-bb42c4d70732|||Laurie Metcalf.jpg'}, {'path': '/nas/dominic/AanaFaceEval/identities_reference/default/00227c4a-8cf5-491f-823d-4bd6251efac1|||Luís Melo.jpg'}, {'path': '/nas/dominic/AanaFaceEval/identities_reference/default/0022e2e0-f72b-4470-af26-0b93527b3ebf|||Marie-Mae van Zuilen.jpg'}]}\n"
     ]
    }
   ],
   "source": [
    "res = extract_face_feats_batched(image_paths[13:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'IndexError',\n",
       " 'message': 'list index out of range',\n",
       " 'data': {},\n",
       " 'stacktrace': '\\x1b[36mray::ServeReplica:facefeat_extractor_deployment:FacefeatureExtractorDeployment.handle_request_with_rejection()\\x1b[39m (pid=9498, ip=172.17.0.3, actor_id=2d13ca81aac0a71ca1ac728801000000, repr=<ray.serve._private.replica.ServeReplica:facefeat_extractor_deployment:FacefeatureExtractorDeployment object at 0x7f035bcd8af0>)\\n    yield await self._user_callable_wrapper.call_user_method(\\n  File \"/root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1150, in call_user_method\\n    raise e from None\\nray.exceptions.RayTaskError: \\x1b[36mray::ServeReplica:facefeat_extractor_deployment:FacefeatureExtractorDeployment.handle_request_with_rejection()\\x1b[39m (pid=9498, ip=172.17.0.3)\\n  File \"/root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/ray/serve/_private/utils.py\", line 168, in wrap_to_ray_error\\n    raise exception\\n  File \"/root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 1132, in call_user_method\\n    await self._call_func_or_gen(\\n  File \"/root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/ray/serve/_private/replica.py\", line 856, in _call_func_or_gen\\n    result = await result\\n  File \"/workspaces/aana_sdk/aana/deployments/face_featureextraction_deployment.py\", line 61, in predict\\n    image_np, face_landmarks[k], image_size=(112, 112), method=\"similar\"\\nIndexError: list index out of range'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 28/33541 [00:07<2:38:11,  3.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/nas/dominic/AanaFaceEval/identities_reference/default/*.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_filepath \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(image_paths):\n\u001b[0;32m---> 17\u001b[0m     face_feats, norms \u001b[38;5;241m=\u001b[39m \u001b[43mextract_face_feats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_filepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#import pdb; pdb.set_trace()\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(face_feats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(face_feats)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m norms[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m19.0\u001b[39m):\n",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m, in \u001b[0;36mextract_face_feats\u001b[0;34m(im_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_face_feats\u001b[39m(im_path):\n\u001b[1;32m      6\u001b[0m     data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      8\u001b[0m         {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m: im_path}\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m     ],\n\u001b[1;32m     11\u001b[0m     }\n\u001b[0;32m---> 13\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://127.0.0.1:8000/recognize_faces\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     res \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface_features_per_image\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface_feats\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface_features_per_image\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorms\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/urllib3/connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/usr/local/python/3.10.14/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/python/3.10.14/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.10.14/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/python/3.10.14/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "reference_faces_dict_30K_webface4M_r101 = {\n",
    "    \"person_names\": [],\n",
    "    \"paths_to_image\": [],\n",
    "    \"face_features\": [],\n",
    "    \"norms\": [],\n",
    "}\n",
    "\n",
    "failed_faces = []\n",
    "\n",
    "image_paths = sorted(\n",
    "    glob.glob(\"/nas/dominic/AanaFaceEval/identities_reference/default/*.jpg\")\n",
    ")\n",
    "\n",
    "for image_filepath in tqdm.tqdm(image_paths):\n",
    "    face_feats, norms = extract_face_feats(image_filepath)\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "    if face_feats is not None and len(face_feats) == 1 and norms[0][0] >= 19.0:\n",
    "        reference_faces_dict_30K_webface4M_r101[\"person_names\"].append(\n",
    "            os.path.basename(image_filepath)[0:-4].split(\"|||\")[-1]\n",
    "        )\n",
    "        reference_faces_dict_30K_webface4M_r101[\"paths_to_image\"].append(image_filepath)\n",
    "        reference_faces_dict_30K_webface4M_r101[\"face_features\"].append(face_feats[0])\n",
    "        reference_faces_dict_30K_webface4M_r101[\"norms\"].append(norms[0][0])\n",
    "    else:\n",
    "        failed_faces.append([image_filepath, norms[0][0]])\n",
    "\n",
    "reverse_reference_faces_dict_30K_webface4M_r101 = {\n",
    "    reference_faces_dict_30K_webface4M_r101[\"person_names\"][\n",
    "        k\n",
    "    ]: reference_faces_dict_30K_webface4M_r101[\"paths_to_image\"][k]\n",
    "    for k in range(len(reference_faces_dict_30K_webface4M_r101[\"person_names\"]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aana-vIr3-B0u-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
