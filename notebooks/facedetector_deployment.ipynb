{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Identification Example\n",
    "\n",
    "The notebook shows how to use face recognition with Aana SDK. Face recognition uses three separate deployments:\n",
    "1. **Face Detection**, which returns bounding boxes and face landmarks (keypoints) for each detected face\n",
    "2. **Face Feature Extraction**, which for a given image and face landmarks returns a face feature that can be used to compare face similarities.\n",
    "3. **Face Database**, which uses 1 and 2 to extract reference faces and populate a reference face database that can be used to search for known identities across image/video collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n",
      "Collecting onnxruntime-gpu\n",
      "  Downloading https://aiinfra.pkgs.visualstudio.com/2692857e-05ef-43b4-ba9c-ccf1c22c437c/_packaging/9387c3aa-d9ad-4513-968c-383f6f7f53b8/pypi/download/onnxruntime-gpu/1.18.1/onnxruntime_gpu-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (201.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.5/201.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: coloredlogs in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from onnxruntime-gpu) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from onnxruntime-gpu) (24.3.25)\n",
      "Requirement already satisfied: numpy<2.0,>=1.21.6 in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from onnxruntime-gpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from onnxruntime-gpu) (24.1)\n",
      "Requirement already satisfied: protobuf in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from onnxruntime-gpu) (5.27.2)\n",
      "Requirement already satisfied: sympy in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from onnxruntime-gpu) (1.13.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
      "Installing collected packages: onnxruntime-gpu\n",
      "Successfully installed onnxruntime-gpu-1.18.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# For onnx GPU support (face detection model), execute this code\n",
    "!pip install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"  # replace with your GPU ID\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"  # replace with your token, required for downloading the model weights and reference face database.\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")  # Ideally we set the token in the terminal. However, it appears to be more difficult to do in a dev container, so doing it like this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mobiuslabsgmbh/aana_facedb/commit/1edf742cb198046ec438ca67d416d0976036f032', commit_message='Upload AdaFace/default32K_ir_101_webface4M.tar with huggingface_hub', commit_description='', oid='1edf742cb198046ec438ca67d416d0976036f032', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import upload_file\n",
    "\n",
    "repo_name = \"mobiuslabsgmbh/aana_facedb\"\n",
    "\n",
    "\n",
    "upload_file(\n",
    "    path_or_fileobj=\"/tmp/aana_data/artifacts/face_features_database/ir_101_webface4M/archive.tar\",\n",
    "    path_in_repo=\"AdaFace/default32K_ir_101_webface4M.tar\",\n",
    "    repo_id=repo_name,\n",
    "    token=HF_TOKEN,\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the face detection deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-18 13:35:23,440\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/root/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_dir\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
      "  warnings.warn(\n",
      "2024-07-18 13:35:25,368\tWARNING api.py:432 -- The default value for `max_ongoing_requests` has changed from 100 to 5 in Ray 2.32.0.\n",
      "2024-07-18 13:35:25,477\tWARNING api.py:432 -- The default value for `max_ongoing_requests` has changed from 100 to 5 in Ray 2.32.0.\n",
      "2024-07-18 13:35:25,512\tWARNING api.py:432 -- The default value for `max_ongoing_requests` has changed from 100 to 5 in Ray 2.32.0.\n",
      "2024-07-18 13:35:27,759\tWARNING services.py:2010 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-07-18 13:35:28,956\tINFO worker.py:1779 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "The new client HTTP config differs from the existing one in the following fields: ['location']. The new HTTP config is ignored.\n",
      "2024-07-18 13:35:33,972\tINFO handle.py:126 -- Created DeploymentHandle 'v7sejk1o' for Deployment(name='FaceDetectorDeployment', app='face_detector').\n",
      "2024-07-18 13:35:33,975\tINFO handle.py:126 -- Created DeploymentHandle 'cpkutg1e' for Deployment(name='FaceDetectorDeployment', app='face_detector').\n",
      "2024-07-18 13:35:38,012\tINFO handle.py:126 -- Created DeploymentHandle 'zjsnypcr' for Deployment(name='FaceDetectorDeployment', app='face_detector').\n",
      "2024-07-18 13:35:38,014\tINFO api.py:609 -- Deployed app 'face_detector' successfully.\n",
      "2024-07-18 13:35:38,027\tINFO handle.py:126 -- Created DeploymentHandle 'w6inefng' for Deployment(name='FaceDetectorDeployment', app='face_detector').\n",
      "2024-07-18 13:35:38,043\tINFO pow_2_scheduler.py:260 -- Got updated replicas for Deployment(name='FaceDetectorDeployment', app='face_detector'): {'vhdbomva'}.\n"
     ]
    }
   ],
   "source": [
    "from aana.deployments.aana_deployment_handle import AanaDeploymentHandle\n",
    "from aana.deployments.face_detection_deployment import (\n",
    "    FaceDetectorConfig,\n",
    "    FaceDetectorDeployment,\n",
    ")\n",
    "\n",
    "from aana.sdk import AanaSDK\n",
    "\n",
    "\n",
    "aana_app = AanaSDK()\n",
    "aana_app.connect(show_logs=False)\n",
    "\n",
    "# Instantiate and register the face detection deployment\n",
    "face_detector_deployment = FaceDetectorDeployment.options(\n",
    "    num_replicas=1,\n",
    "    ray_actor_options={\"num_gpus\": 0.1},\n",
    "    user_config=FaceDetectorConfig(\n",
    "        nms_thresh=0.4,\n",
    "        batch_size=4,\n",
    "        input_size=640,\n",
    "    ).model_dump(mode=\"json\"),\n",
    ")\n",
    "\n",
    "aana_app.register_deployment(\"face_detector\", face_detector_deployment, deploy=True)\n",
    "facedetector_handle = await AanaDeploymentHandle.create(\"face_detector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the face feature extraction deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 13:35:43,838\tWARNING api.py:432 -- The default value for `max_ongoing_requests` has changed from 100 to 5 in Ray 2.32.0.\n",
      "The new client HTTP config differs from the existing one in the following fields: ['location']. The new HTTP config is ignored.\n",
      "2024-07-18 13:35:43,850\tINFO handle.py:126 -- Created DeploymentHandle 'zlgmax72' for Deployment(name='FacefeatureExtractorDeployment', app='facefeat_extractor').\n",
      "2024-07-18 13:35:43,852\tINFO handle.py:126 -- Created DeploymentHandle 'dfeuvecs' for Deployment(name='FacefeatureExtractorDeployment', app='facefeat_extractor').\n",
      "2024-07-18 13:35:51,911\tINFO handle.py:126 -- Created DeploymentHandle 'tjzh74sl' for Deployment(name='FacefeatureExtractorDeployment', app='facefeat_extractor').\n",
      "2024-07-18 13:35:51,914\tINFO api.py:609 -- Deployed app 'facefeat_extractor' successfully.\n",
      "2024-07-18 13:35:51,923\tINFO handle.py:126 -- Created DeploymentHandle 'siv9jsyf' for Deployment(name='FacefeatureExtractorDeployment', app='facefeat_extractor').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 13:35:51,935\tINFO pow_2_scheduler.py:260 -- Got updated replicas for Deployment(name='FacefeatureExtractorDeployment', app='facefeat_extractor'): {'i6t0ad8j'}.\n",
      "2024-07-18 13:36:30,392\tINFO pow_2_scheduler.py:260 -- Got updated replicas for Deployment(name='FaceDatabaseDeployment', app='face_database'): {'lhjnntdy'}.\n",
      "2024-07-18 14:45:55,939\tINFO pow_2_scheduler.py:260 -- Got updated replicas for Deployment(name='FaceDetectorDeployment', app='face_detector'): set().\n",
      "2024-07-18 14:45:55,950\tINFO pow_2_scheduler.py:260 -- Got updated replicas for Deployment(name='FacefeatureExtractorDeployment', app='facefeat_extractor'): set().\n",
      "2024-07-18 14:45:55,953\tINFO pow_2_scheduler.py:260 -- Got updated replicas for Deployment(name='FaceDatabaseDeployment', app='face_database'): set().\n"
     ]
    }
   ],
   "source": [
    "from aana.deployments.face_featureextraction_deployment import (\n",
    "    FacefeatureExtractorConfig,\n",
    "    FacefeatureExtractorDeployment,\n",
    ")\n",
    "\n",
    "FACEFEATURE_MODEL = \"ir_101_webface4M\"  # Name of the face feature model to be used. This has to be the same one for face feature extraction deployment and reference face database.\n",
    "\n",
    "# Instantiate and register the face feature extraction deployment\n",
    "facefeat_extractor_deployment = FacefeatureExtractorDeployment.options(\n",
    "    num_replicas=1,\n",
    "    ray_actor_options={\"num_gpus\": 0.2},\n",
    "    user_config=FacefeatureExtractorConfig(\n",
    "        feature_extractor_name=FACEFEATURE_MODEL,\n",
    "        min_face_norm=19.0,\n",
    "    ).model_dump(mode=\"json\"),\n",
    ")\n",
    "\n",
    "aana_app.register_deployment(\n",
    "    \"facefeat_extractor\", facefeat_extractor_deployment, deploy=True\n",
    ")\n",
    "facefeat_handle = await AanaDeploymentHandle.create(\"facefeat_extractor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the reference face database deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 13:36:14,232\tWARNING api.py:432 -- The default value for `max_ongoing_requests` has changed from 100 to 5 in Ray 2.32.0.\n",
      "2024-07-18 13:36:14,247\tWARNING api.py:432 -- The default value for `max_ongoing_requests` has changed from 100 to 5 in Ray 2.32.0.\n",
      "The new client HTTP config differs from the existing one in the following fields: ['location']. The new HTTP config is ignored.\n",
      "2024-07-18 13:36:14,266\tINFO handle.py:126 -- Created DeploymentHandle 'czwffmj6' for Deployment(name='FaceDatabaseDeployment', app='face_database').\n",
      "2024-07-18 13:36:14,267\tINFO handle.py:126 -- Created DeploymentHandle 'm0mukgfj' for Deployment(name='FaceDatabaseDeployment', app='face_database').\n",
      "2024-07-18 13:36:30,368\tINFO handle.py:126 -- Created DeploymentHandle 'v4zxmuqg' for Deployment(name='FaceDatabaseDeployment', app='face_database').\n",
      "2024-07-18 13:36:30,369\tINFO api.py:609 -- Deployed app 'face_database' successfully.\n",
      "2024-07-18 13:36:30,380\tINFO handle.py:126 -- Created DeploymentHandle 'aczix7dx' for Deployment(name='FaceDatabaseDeployment', app='face_database').\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import aana.deployments.face_database_deployment\n",
    "\n",
    "importlib.reload(aana.deployments.face_database_deployment)\n",
    "\n",
    "from aana.configs.settings import settings\n",
    "from aana.deployments.face_database_deployment import (\n",
    "    FaceDatabaseConfig,\n",
    "    FaceDatabaseDeployment,\n",
    ")\n",
    "\n",
    "face_database_deployment = FaceDatabaseDeployment.options(\n",
    "    num_replicas=1,\n",
    "    ray_actor_options={\"num_gpus\": 0.1},\n",
    "    user_config=FaceDatabaseConfig(\n",
    "        face_threshold=1.18,\n",
    "        facenorm_threshold=18.0,\n",
    "        face_features_directory=settings.artifacts_dir / \"face_features_database\",\n",
    "        feature_extractor_name=FACEFEATURE_MODEL,\n",
    "        hugging_face_token=HF_TOKEN,\n",
    "    ).model_dump(mode=\"json\"),\n",
    ")\n",
    "\n",
    "aana_app.register_deployment(\"face_database\", face_database_deployment, deploy=True)\n",
    "\n",
    "facedatabase_handle = await AanaDeploymentHandle.create(\"face_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import tarfile\n",
    "facefeat_directory = '/tmp/aana_data/artifacts/face_features_database/ir_101_webface4M'\n",
    "path_to_tarfile = hf_hub_download(\n",
    "                    repo_id=\"mobiuslabsgmbh/aana_facedb\",\n",
    "                    repo_type='dataset',\n",
    "                    filename=\"AdaFace/default32K_ir_101_webface4M.tar\",\n",
    "                    local_dir=facefeat_directory,\n",
    "                    token=HF_TOKEN,\n",
    "                    \n",
    "                )\n",
    "#Open the tar file and extract its contents\n",
    "with tarfile.open(path_to_tarfile, \"r:*\") as tar:\n",
    "    tar.extractall(path=facefeat_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 13:36:35,011\tINFO handle.py:126 -- Created DeploymentHandle '0swab8x9' for Deployment(name='FaceDetectorDeployment', app='face_detector').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounding_boxes': [array([[415.59457   ,  96.23158   , 481.6673    , 184.54308   ,\n",
      "          0.87722456],\n",
      "       [188.31061   ,  60.958458  , 272.11404   , 174.89207   ,\n",
      "          0.7909324 ]], dtype=float32)], 'keypoints': [array([[[443.3935 , 131.3212 ],\n",
      "        [471.51398, 133.13217],\n",
      "        [462.67175, 147.79501],\n",
      "        [447.37967, 164.56483],\n",
      "        [467.67795, 165.76624]],\n",
      "\n",
      "       [[232.06563, 103.42656],\n",
      "        [264.94907, 106.04597],\n",
      "        [261.4791 , 123.83058],\n",
      "        [233.09895, 144.04256],\n",
      "        [261.0374 , 146.01912]]], dtype=float32)]}\n"
     ]
    }
   ],
   "source": [
    "from aana.core.models.image import Image\n",
    "from pathlib import Path\n",
    "\n",
    "image = Image(\n",
    "    path=Path(\n",
    "        \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000101.jpg\"\n",
    "    )\n",
    ")\n",
    "\n",
    "detector_output = await facedetector_handle.predict([image])\n",
    "\n",
    "print(detector_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 13:36:36,935\tINFO handle.py:126 -- Created DeploymentHandle 'a3o091x2' for Deployment(name='FaceDetectorDeployment', app='face_detector').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounding_boxes': [array([[415.59457   ,  96.23158   , 481.6673    , 184.54308   ,\n",
      "          0.87722456],\n",
      "       [188.31061   ,  60.958458  , 272.11404   , 174.89207   ,\n",
      "          0.7909324 ]], dtype=float32), array([[418.13217   ,  91.993866  , 484.82758   , 182.29898   ,\n",
      "          0.86423916],\n",
      "       [174.74506   ,  57.504745  , 258.35153   , 175.60551   ,\n",
      "          0.79931784]], dtype=float32), array([[409.99353   ,  92.0741    , 477.31976   , 182.75638   ,\n",
      "          0.86028343],\n",
      "       [170.32983   ,  63.222565  , 253.86038   , 180.34108   ,\n",
      "          0.77052784]], dtype=float32), array([[402.97488   ,  91.797035  , 470.39627   , 182.33727   ,\n",
      "          0.8626434 ],\n",
      "       [176.70801   ,  65.474434  , 262.6093    , 185.3455    ,\n",
      "          0.80597097]], dtype=float32), array([[409.70914   ,  94.12892   , 477.73315   , 184.83496   ,\n",
      "          0.86796105],\n",
      "       [194.3403    ,  62.5718    , 283.30243   , 181.06514   ,\n",
      "          0.7984799 ]], dtype=float32), array([[418.13217   ,  91.993866  , 484.82758   , 182.29898   ,\n",
      "          0.86423916],\n",
      "       [174.74506   ,  57.504745  , 258.35153   , 175.60551   ,\n",
      "          0.79931784]], dtype=float32), array([[409.99353   ,  92.0741    , 477.31976   , 182.75638   ,\n",
      "          0.86028343],\n",
      "       [170.32983   ,  63.222565  , 253.86038   , 180.34108   ,\n",
      "          0.77052784]], dtype=float32), array([[402.97488   ,  91.797035  , 470.39627   , 182.33727   ,\n",
      "          0.8626434 ],\n",
      "       [176.70801   ,  65.474434  , 262.6093    , 185.3455    ,\n",
      "          0.80597097]], dtype=float32), array([[409.70914   ,  94.12892   , 477.73315   , 184.83496   ,\n",
      "          0.86796105],\n",
      "       [194.3403    ,  62.5718    , 283.30243   , 181.06514   ,\n",
      "          0.7984799 ]], dtype=float32), array([[423.68268   ,  90.93642   , 491.57736   , 182.98924   ,\n",
      "          0.86578596],\n",
      "       [188.37244   ,  60.735405  , 279.81073   , 182.54686   ,\n",
      "          0.76678604]], dtype=float32)], 'keypoints': [array([[[443.3935 , 131.3212 ],\n",
      "        [471.51398, 133.13217],\n",
      "        [462.67175, 147.79501],\n",
      "        [447.37967, 164.56483],\n",
      "        [467.67795, 165.76624]],\n",
      "\n",
      "       [[232.06563, 103.42656],\n",
      "        [264.94907, 106.04597],\n",
      "        [261.4791 , 123.83058],\n",
      "        [233.09895, 144.04256],\n",
      "        [261.0374 , 146.01912]]], dtype=float32), array([[[445.97455, 128.60817],\n",
      "        [474.23828, 130.22504],\n",
      "        [465.7228 , 144.57536],\n",
      "        [449.39145, 161.88483],\n",
      "        [470.22974, 163.0912 ]],\n",
      "\n",
      "       [[214.46033, 103.47568],\n",
      "        [248.99437, 104.69819],\n",
      "        [242.49216, 124.53039],\n",
      "        [216.07947, 145.12016],\n",
      "        [245.56854, 145.95969]]], dtype=float32), array([[[438.46002 , 127.9688  ],\n",
      "        [467.52863 , 129.99774 ],\n",
      "        [458.35834 , 144.89586 ],\n",
      "        [441.99426 , 162.20888 ],\n",
      "        [463.41315 , 163.63889 ]],\n",
      "\n",
      "       [[213.05591 , 110.092804],\n",
      "        [246.42421 , 111.94353 ],\n",
      "        [240.71036 , 133.9882  ],\n",
      "        [212.93536 , 151.2478  ],\n",
      "        [241.13043 , 152.6183  ]]], dtype=float32), array([[[431.38477 , 128.68895 ],\n",
      "        [460.09018 , 129.48239 ],\n",
      "        [451.39886 , 145.5343  ],\n",
      "        [434.93936 , 162.37599 ],\n",
      "        [455.47836 , 162.95996 ]],\n",
      "\n",
      "       [[224.53983 , 114.2865  ],\n",
      "        [256.04007 , 114.531494],\n",
      "        [254.00334 , 136.4155  ],\n",
      "        [223.20392 , 155.10492 ],\n",
      "        [250.7821  , 155.40808 ]]], dtype=float32), array([[[437.07846 , 130.36234 ],\n",
      "        [466.88522 , 131.63586 ],\n",
      "        [456.64526 , 146.95953 ],\n",
      "        [441.0925  , 164.79419 ],\n",
      "        [462.43216 , 165.6739  ]],\n",
      "\n",
      "       [[248.5597  , 108.08049 ],\n",
      "        [277.6056  , 108.687744],\n",
      "        [278.6718  , 131.68224 ],\n",
      "        [245.3452  , 150.19109 ],\n",
      "        [270.66766 , 151.29375 ]]], dtype=float32), array([[[445.97455, 128.60817],\n",
      "        [474.23828, 130.22504],\n",
      "        [465.7228 , 144.57536],\n",
      "        [449.39145, 161.88483],\n",
      "        [470.22974, 163.0912 ]],\n",
      "\n",
      "       [[214.46033, 103.47568],\n",
      "        [248.99437, 104.69819],\n",
      "        [242.49216, 124.53039],\n",
      "        [216.07947, 145.12016],\n",
      "        [245.56854, 145.95969]]], dtype=float32), array([[[438.46002 , 127.9688  ],\n",
      "        [467.52863 , 129.99774 ],\n",
      "        [458.35834 , 144.89586 ],\n",
      "        [441.99426 , 162.20888 ],\n",
      "        [463.41315 , 163.63889 ]],\n",
      "\n",
      "       [[213.05591 , 110.092804],\n",
      "        [246.42421 , 111.94353 ],\n",
      "        [240.71036 , 133.9882  ],\n",
      "        [212.93536 , 151.2478  ],\n",
      "        [241.13043 , 152.6183  ]]], dtype=float32), array([[[431.38477 , 128.68895 ],\n",
      "        [460.09018 , 129.48239 ],\n",
      "        [451.39886 , 145.5343  ],\n",
      "        [434.93936 , 162.37599 ],\n",
      "        [455.47836 , 162.95996 ]],\n",
      "\n",
      "       [[224.53983 , 114.2865  ],\n",
      "        [256.04007 , 114.531494],\n",
      "        [254.00334 , 136.4155  ],\n",
      "        [223.20392 , 155.10492 ],\n",
      "        [250.7821  , 155.40808 ]]], dtype=float32), array([[[437.07846 , 130.36234 ],\n",
      "        [466.88522 , 131.63586 ],\n",
      "        [456.64526 , 146.95953 ],\n",
      "        [441.0925  , 164.79419 ],\n",
      "        [462.43216 , 165.6739  ]],\n",
      "\n",
      "       [[248.5597  , 108.08049 ],\n",
      "        [277.6056  , 108.687744],\n",
      "        [278.6718  , 131.68224 ],\n",
      "        [245.3452  , 150.19109 ],\n",
      "        [270.66766 , 151.29375 ]]], dtype=float32), array([[[449.771  , 128.27423],\n",
      "        [480.11145, 128.84871],\n",
      "        [469.44055, 144.82503],\n",
      "        [453.78052, 162.73204],\n",
      "        [476.1742 , 163.1264 ]],\n",
      "\n",
      "       [[243.21823, 105.1582 ],\n",
      "        [272.66202, 107.5807 ],\n",
      "        [273.41522, 129.80507],\n",
      "        [241.24968, 149.8668 ],\n",
      "        [265.76196, 152.4449 ]]], dtype=float32)]}\n"
     ]
    }
   ],
   "source": [
    "images = [\n",
    "    Image(\n",
    "        path=Path(\n",
    "            \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000101.jpg\"\n",
    "        )\n",
    "    ),\n",
    "    Image(\n",
    "        path=Path(\n",
    "            \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000102.jpg\"\n",
    "        )\n",
    "    ),\n",
    "    Image(\n",
    "        path=Path(\n",
    "            \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000103.jpg\"\n",
    "        )\n",
    "    ),\n",
    "    Image(\n",
    "        path=Path(\n",
    "            \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000104.jpg\"\n",
    "        )\n",
    "    ),\n",
    "    Image(\n",
    "        path=Path(\n",
    "            \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000105.jpg\"\n",
    "        )\n",
    "    ),\n",
    "    Image(\n",
    "        path=Path(\n",
    "            \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000102.jpg\"\n",
    "        )\n",
    "    ),\n",
    "    Image(\n",
    "        path=Path(\n",
    "            \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000103.jpg\"\n",
    "        )\n",
    "    ),\n",
    "    Image(\n",
    "        path=Path(\n",
    "            \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000104.jpg\"\n",
    "        )\n",
    "    ),\n",
    "    Image(\n",
    "        path=Path(\n",
    "            \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000105.jpg\"\n",
    "        )\n",
    "    ),\n",
    "    Image(\n",
    "        path=Path(\n",
    "            \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000106.jpg\"\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "\n",
    "detector_output = await facedetector_handle.predict(images)\n",
    "\n",
    "print(detector_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Face feature extraction using the output of the face detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 13:36:41,655\tINFO handle.py:126 -- Created DeploymentHandle 'wiwqzles' for Deployment(name='FacefeatureExtractorDeployment', app='facefeat_extractor').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'facefeats_per_image': [{'face_feats': array([[-0.04401124, -0.0272526 ,  0.01495183, ..., -0.06465618,\n",
      "         0.0389987 ,  0.0128512 ],\n",
      "       [ 0.01096947, -0.02446904,  0.03266014, ..., -0.01851118,\n",
      "         0.01181385,  0.02578571]], dtype=float32), 'norms': array([[21.607306],\n",
      "       [23.78863 ]], dtype=float32)}, {'face_feats': array([[-0.03572392, -0.04950345,  0.00264802, ..., -0.05969051,\n",
      "         0.02760378,  0.0097962 ],\n",
      "       [ 0.02021521, -0.01210909,  0.04694788, ...,  0.00210422,\n",
      "         0.00151184,  0.05000335]], dtype=float32), 'norms': array([[22.046799],\n",
      "       [23.471266]], dtype=float32)}, {'face_feats': array([[-0.04562347, -0.0468936 , -0.00619584, ..., -0.06936102,\n",
      "         0.03672777, -0.00146778],\n",
      "       [ 0.01352969, -0.01935948,  0.04992234, ..., -0.00231571,\n",
      "         0.00225516,  0.03048169]], dtype=float32), 'norms': array([[21.70192 ],\n",
      "       [23.681787]], dtype=float32)}, {'face_feats': array([[-0.05637712, -0.04676075,  0.0011431 , ..., -0.07301167,\n",
      "         0.04571754,  0.01712126],\n",
      "       [ 0.01619553, -0.0266506 ,  0.05035165, ..., -0.02997553,\n",
      "        -0.00241095,  0.0197979 ]], dtype=float32), 'norms': array([[22.247034],\n",
      "       [23.891937]], dtype=float32)}, {'face_feats': array([[-0.05200328, -0.04098802, -0.00280165, ..., -0.07998914,\n",
      "         0.04286859,  0.01795766],\n",
      "       [-0.00780398, -0.00293579,  0.04705197, ..., -0.00812636,\n",
      "        -0.01053979, -0.00702198]], dtype=float32), 'norms': array([[21.895561],\n",
      "       [24.513987]], dtype=float32)}, {'face_feats': array([[-0.03572392, -0.04950345,  0.00264802, ..., -0.05969051,\n",
      "         0.02760378,  0.0097962 ],\n",
      "       [ 0.02021521, -0.01210909,  0.04694788, ...,  0.00210422,\n",
      "         0.00151184,  0.05000335]], dtype=float32), 'norms': array([[22.046799],\n",
      "       [23.471266]], dtype=float32)}, {'face_feats': array([[-0.04562347, -0.0468936 , -0.00619584, ..., -0.06936102,\n",
      "         0.03672777, -0.00146778],\n",
      "       [ 0.01352969, -0.01935948,  0.04992234, ..., -0.00231571,\n",
      "         0.00225516,  0.03048169]], dtype=float32), 'norms': array([[21.70192 ],\n",
      "       [23.681787]], dtype=float32)}, {'face_feats': array([[-0.05637712, -0.04676075,  0.0011431 , ..., -0.07301167,\n",
      "         0.04571754,  0.01712126],\n",
      "       [ 0.01619553, -0.0266506 ,  0.05035165, ..., -0.02997553,\n",
      "        -0.00241095,  0.0197979 ]], dtype=float32), 'norms': array([[22.247034],\n",
      "       [23.891937]], dtype=float32)}, {'face_feats': array([[-0.05200328, -0.04098802, -0.00280165, ..., -0.07998914,\n",
      "         0.04286859,  0.01795766],\n",
      "       [-0.00780398, -0.00293579,  0.04705197, ..., -0.00812636,\n",
      "        -0.01053979, -0.00702198]], dtype=float32), 'norms': array([[21.895561],\n",
      "       [24.513987]], dtype=float32)}, {'face_feats': array([[-0.04453743, -0.03764678,  0.00768797, ..., -0.07023441,\n",
      "         0.03601365,  0.00223277],\n",
      "       [-0.00771328, -0.02530563,  0.04285207, ..., -0.02787509,\n",
      "        -0.01446716,  0.01034789]], dtype=float32), 'norms': array([[21.661755],\n",
      "       [23.185188]], dtype=float32)}]}\n"
     ]
    }
   ],
   "source": [
    "keypoints = detector_output[\"keypoints\"]\n",
    "facefeat_output = await facefeat_handle.predict(images, keypoints)\n",
    "\n",
    "print(facefeat_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search the reference face database with the face features we extracted above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 13:36:47,414\tINFO handle.py:126 -- Created DeploymentHandle 'rdm5p6fu' for Deployment(name='FaceDatabaseDeployment', app='face_database').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32898 identities in the reference face database.\n",
      "The first 10 are: ['Paola Minaccioni', 'Yann Hnautra', 'Anna Raadsveld', 'Charlotte Arnold', 'Dustin Clare', 'Erica Carroll', 'J.A. Bayona', 'Kathryn Bigelow', 'Yon González', 'Gil Darnell']\n"
     ]
    }
   ],
   "source": [
    "all_identities_in_database = await facedatabase_handle.get_all_identities()\n",
    "\n",
    "print(\n",
    "    \"There are {} identities in the reference face database.\".format(\n",
    "        len(all_identities_in_database)\n",
    "    )\n",
    ")\n",
    "print(\"The first 10 are: {}\".format(all_identities_in_database[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 13:37:18,760\tINFO handle.py:126 -- Created DeploymentHandle 'jgo7goc5' for Deployment(name='FaceDatabaseDeployment', app='face_database').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identities_per_image': [[{'person_id': 'Donna Murphy', 'image_id': '587eed19-0fd7-4f1b-8911-e347f86b1bc8', 'distance': 0.7868431806564331, 'norm': 21.607306, 'quality': 'good'}, {'person_id': 'Patrick Stewart', 'image_id': '00a35c5b-aacf-4574-8219-9c4cb36486a4', 'distance': 0.7150369882583618, 'norm': 23.78863, 'quality': 'good'}], [{'person_id': 'Donna Murphy', 'image_id': '587eed19-0fd7-4f1b-8911-e347f86b1bc8', 'distance': 0.8411625623703003, 'norm': 22.046799, 'quality': 'good'}, {'person_id': 'Patrick Stewart', 'image_id': '00a35c5b-aacf-4574-8219-9c4cb36486a4', 'distance': 0.6993443965911865, 'norm': 23.471266, 'quality': 'good'}], [{'person_id': 'Donna Murphy', 'image_id': '587eed19-0fd7-4f1b-8911-e347f86b1bc8', 'distance': 0.8204156756401062, 'norm': 21.70192, 'quality': 'good'}, {'person_id': 'Patrick Stewart', 'image_id': '00a35c5b-aacf-4574-8219-9c4cb36486a4', 'distance': 0.6765266060829163, 'norm': 23.681787, 'quality': 'good'}], [{'person_id': 'Donna Murphy', 'image_id': '587eed19-0fd7-4f1b-8911-e347f86b1bc8', 'distance': 0.8992512226104736, 'norm': 22.247034, 'quality': 'good'}, {'person_id': 'Patrick Stewart', 'image_id': '00a35c5b-aacf-4574-8219-9c4cb36486a4', 'distance': 0.6463454961776733, 'norm': 23.891937, 'quality': 'good'}], [{'person_id': 'Donna Murphy', 'image_id': '587eed19-0fd7-4f1b-8911-e347f86b1bc8', 'distance': 0.8130040764808655, 'norm': 21.895561, 'quality': 'good'}, {'person_id': 'Patrick Stewart', 'image_id': '00a35c5b-aacf-4574-8219-9c4cb36486a4', 'distance': 0.7532812356948853, 'norm': 24.513987, 'quality': 'good'}], [{'person_id': 'Donna Murphy', 'image_id': '587eed19-0fd7-4f1b-8911-e347f86b1bc8', 'distance': 0.8411625623703003, 'norm': 22.046799, 'quality': 'good'}, {'person_id': 'Patrick Stewart', 'image_id': '00a35c5b-aacf-4574-8219-9c4cb36486a4', 'distance': 0.6993443965911865, 'norm': 23.471266, 'quality': 'good'}], [{'person_id': 'Donna Murphy', 'image_id': '587eed19-0fd7-4f1b-8911-e347f86b1bc8', 'distance': 0.8204156756401062, 'norm': 21.70192, 'quality': 'good'}, {'person_id': 'Patrick Stewart', 'image_id': '00a35c5b-aacf-4574-8219-9c4cb36486a4', 'distance': 0.6765266060829163, 'norm': 23.681787, 'quality': 'good'}], [{'person_id': 'Donna Murphy', 'image_id': '587eed19-0fd7-4f1b-8911-e347f86b1bc8', 'distance': 0.8992512226104736, 'norm': 22.247034, 'quality': 'good'}, {'person_id': 'Patrick Stewart', 'image_id': '00a35c5b-aacf-4574-8219-9c4cb36486a4', 'distance': 0.6463454961776733, 'norm': 23.891937, 'quality': 'good'}], [{'person_id': 'Donna Murphy', 'image_id': '587eed19-0fd7-4f1b-8911-e347f86b1bc8', 'distance': 0.8130040764808655, 'norm': 21.895561, 'quality': 'good'}, {'person_id': 'Patrick Stewart', 'image_id': '00a35c5b-aacf-4574-8219-9c4cb36486a4', 'distance': 0.7532812356948853, 'norm': 24.513987, 'quality': 'good'}], [{'person_id': 'Donna Murphy', 'image_id': '587eed19-0fd7-4f1b-8911-e347f86b1bc8', 'distance': 0.8629156351089478, 'norm': 21.661755, 'quality': 'good'}, {'person_id': 'Patrick Stewart', 'image_id': '00a35c5b-aacf-4574-8219-9c4cb36486a4', 'distance': 0.7982269525527954, 'norm': 23.185188, 'quality': 'good'}]]}\n"
     ]
    }
   ],
   "source": [
    "recognized_faces = await facedatabase_handle.identify_faces(\n",
    "    facefeat_output[\"facefeats_per_image\"]\n",
    ")\n",
    "print(recognized_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUG (Ignore anything below here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aana.configs.settings import settings\n",
    "import importlib\n",
    "import aana.deployments.face_database_deployment\n",
    "\n",
    "importlib.reload(aana.deployments.face_database_deployment)\n",
    "from aana.deployments.face_database_deployment import (\n",
    "    FaceDatabaseConfig,\n",
    "    FaceDatabaseDeployment,\n",
    ")\n",
    "\n",
    "\n",
    "facedatabase_config = FaceDatabaseConfig(\n",
    "    face_threshold=1.18,\n",
    "    facenorm_threshold=19.0,\n",
    "    face_features_directory=settings.artifacts_dir / \"face_features_database\",\n",
    "    feature_extractor_name=FACEFEATURE_MODEL,\n",
    ")\n",
    "facedatabase_deployment = FaceDatabaseDeployment()\n",
    "await facedatabase_deployment.apply_config(facedatabase_config.model_dump(mode=\"json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "facefeats_ir101_web4M = np.load(\n",
    "    \"/nas/dominic/AanaFaceEval/reference_facedict_aanasdk_webface4M_r101.npy\",\n",
    "    allow_pickle=True,\n",
    ").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['person_names', 'paths_to_image', 'face_features', 'norms'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facefeats_ir101_web4M.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32898/32898 [08:15<00:00, 66.43it/s] \n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "for k in tqdm.tqdm(range(len(facefeats_ir101_web4M[\"face_features\"]))):\n",
    "    ffeat = facefeats_ir101_web4M[\"face_features\"][k]\n",
    "    name_ = facefeats_ir101_web4M[\"person_names\"][k]\n",
    "    norm = facefeats_ir101_web4M[\"norms\"][k]\n",
    "    img_id = (\n",
    "        facefeats_ir101_web4M[\"paths_to_image\"][k].split(\"|||\")[0].split(\"/\")[-1]\n",
    "    )  # eg '000744f4-4131-44db-a569-ca211fa55a48'\n",
    "\n",
    "    # res = await facedatabase_handle.add_reference_face(\n",
    "    #     ffeat, person_name=name_, image_id=img_id\n",
    "    # )\n",
    "    res = await facedatabase_deployment.add_reference_face(\n",
    "        ffeat, face_norm=norm, person_name=name_, image_id=img_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': [{'path': '/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000101.jpg'}, {'path': '/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000102.jpg'}, {'path': '/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000103.jpg'}, {'path': '/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000104.jpg'}, {'path': '/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000105.jpg'}, {'path': '/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000106.jpg'}, {'path': '/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000107.jpg'}, {'path': '/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000108.jpg'}, {'path': '/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000109.jpg'}, {'path': '/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000110.jpg'}]}\n"
     ]
    }
   ],
   "source": [
    "# Sample image paths\n",
    "image_paths = [\n",
    "    \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000101.jpg\",\n",
    "    \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000102.jpg\",\n",
    "    \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000103.jpg\",\n",
    "    \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000104.jpg\",\n",
    "    \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000105.jpg\",\n",
    "    \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000106.jpg\",\n",
    "    \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000107.jpg\",\n",
    "    \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000108.jpg\",\n",
    "    \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000109.jpg\",\n",
    "    \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000110.jpg\",\n",
    "]\n",
    "\n",
    "# Populate the data dictionary\n",
    "data = {\"images\": [{\"path\": im_path} for im_path in image_paths[0:10]]}\n",
    "\n",
    "# Print the result\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "\n",
    "def extract_face_feats(im_path):\n",
    "    data = {\n",
    "        \"images\": [{\"path\": im_path}],\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        \"http://127.0.0.1:8000/recognize_faces\",\n",
    "        data={\"body\": json.dumps(data)},\n",
    "        stream=False,\n",
    "    )\n",
    "    res = response.json()\n",
    "\n",
    "    return res\n",
    "    # return res['face_features_per_image'][0]['face_feats'], res['face_features_per_image'][0]['norms']\n",
    "\n",
    "\n",
    "def extract_face_feats_batched(im_paths):\n",
    "    data = {\"images\": [{\"path\": im_path} for im_path in im_paths]}\n",
    "\n",
    "    print(data)\n",
    "\n",
    "    response = requests.post(\n",
    "        \"http://127.0.0.1:8000/recognize_faces\",\n",
    "        data={\"body\": json.dumps(data)},\n",
    "        stream=False,\n",
    "    )\n",
    "    res = response.json()\n",
    "\n",
    "    return res\n",
    "\n",
    "    # face_feats = [res['face_features_per_image'][k]['face_feats'] for k in range(len(res['face_features_per_image']))]\n",
    "    # norms = [res['face_features_per_image'][k]['norms'] for k in range(len(res['face_features_per_image']))]\n",
    "\n",
    "    # return face_feats, norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = extract_face_feats(\n",
    "    \"/nas/datasets/CondensedMoviesLite/AllFrames_3fps/-1gCG8m1SHU/000000000.jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'identified_faces': {'identities_per_image': ['No faces identified']}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "video = {\n",
    "    \"url\": \"https://www.youtube.com/watch?v=wxN1T1uxQ2g\",  # Video URL, Aana SDK supports URLs (including YouTube), file paths or even raw video data\n",
    "    \"media_id\": \"wxN1T1uxQ2g\",  # Media ID, so we can ask questions about the video later by using this ID\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"video_params\": {\n",
    "        \"fast_mode_enabled\": True,  # Enable fast mode, which only processes keyframes\n",
    "    },\n",
    "    \"video\": video,\n",
    "}\n",
    "\n",
    "url = \"http://127.0.0.1:8000/recognize_faces_video\"\n",
    "response = requests.post(url, data={\"body\": json.dumps(data)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'identified_faces_per_frame': [{'identities_per_image': ['No faces identified',\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.0091123580932617,\n",
       "      'norm': 20.947765,\n",
       "      'quality': 'good'}],\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.523160696029663,\n",
       "      'norm': 20.608948,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'James Hong',\n",
       "      'image_id': 'de9c8e31-524e-4667-8c25-5f33dfb992d0',\n",
       "      'distance': 0.8738778829574585,\n",
       "      'norm': 22.890907,\n",
       "      'quality': 'good'},\n",
       "     {'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 0.9786652326583862,\n",
       "      'norm': 21.262327,\n",
       "      'quality': 'good'}],\n",
       "    'No faces identified',\n",
       "    'No faces identified']},\n",
       "  {'identities_per_image': [[{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.225785255432129,\n",
       "      'norm': 21.113794,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Jamie Lee Curtis',\n",
       "      'image_id': '8be86688-b214-4828-89da-7ffc5c12f562',\n",
       "      'distance': 1.1333513259887695,\n",
       "      'norm': 21.329767,\n",
       "      'quality': 'good'}],\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.264506220817566,\n",
       "      'norm': 20.377798,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4157299995422363,\n",
       "      'norm': 20.634789,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.0746777057647705,\n",
       "      'norm': 21.15936,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.1084766387939453,\n",
       "      'norm': 20.714888,\n",
       "      'quality': 'good'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.5023524761199951,\n",
       "      'norm': 22.060068,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.5252913236618042,\n",
       "      'norm': 21.826666,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4279900789260864,\n",
       "      'norm': 20.925854,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.505525827407837,\n",
       "      'norm': 20.04492,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.5269038677215576,\n",
       "      'norm': 19.670021,\n",
       "      'quality': 'bad'}]]},\n",
       "  {'identities_per_image': ['No faces identified',\n",
       "    'No faces identified',\n",
       "    'No faces identified',\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'Jamie Lee Curtis',\n",
       "      'image_id': '8be86688-b214-4828-89da-7ffc5c12f562',\n",
       "      'distance': 1.1101088523864746,\n",
       "      'norm': 21.77221,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.0496032238006592,\n",
       "      'norm': 20.772228,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'Jamie Lee Curtis',\n",
       "      'image_id': '8be86688-b214-4828-89da-7ffc5c12f562',\n",
       "      'distance': 1.1499398946762085,\n",
       "      'norm': 21.09845,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.349351167678833,\n",
       "      'norm': 21.601433,\n",
       "      'quality': 'bad'}]]},\n",
       "  {'identities_per_image': [[{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.5803658962249756,\n",
       "      'norm': 19.543896,\n",
       "      'quality': 'bad'}],\n",
       "    'No faces identified',\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4253437519073486,\n",
       "      'norm': 19.321903,\n",
       "      'quality': 'bad'}],\n",
       "    'No faces identified',\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'Ke Huy Quan',\n",
       "      'image_id': 'f86a4eaa-5839-4a34-bb09-37782cdec90e',\n",
       "      'distance': 0.6039344072341919,\n",
       "      'norm': 20.466648,\n",
       "      'quality': 'good'},\n",
       "     {'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.0413720607757568,\n",
       "      'norm': 20.993013,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.3527483940124512,\n",
       "      'norm': 22.776247,\n",
       "      'quality': 'bad'}]]},\n",
       "  {'identities_per_image': [[{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.029735803604126,\n",
       "      'norm': 20.14292,\n",
       "      'quality': 'good'}],\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.426213264465332,\n",
       "      'norm': 19.8106,\n",
       "      'quality': 'bad'}],\n",
       "    'No faces identified',\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.0891484022140503,\n",
       "      'norm': 19.854485,\n",
       "      'quality': 'good'}],\n",
       "    'No faces identified',\n",
       "    'No faces identified']},\n",
       "  {'identities_per_image': [[{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.2715562582015991,\n",
       "      'norm': 19.235987,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.206167459487915,\n",
       "      'norm': 20.422562,\n",
       "      'quality': 'bad'}],\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.312005877494812,\n",
       "      'norm': 19.463995,\n",
       "      'quality': 'bad'}],\n",
       "    'No faces identified',\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.3651602268218994,\n",
       "      'norm': 19.26259,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.186856746673584,\n",
       "      'norm': 19.846087,\n",
       "      'quality': 'bad'}]]},\n",
       "  {'identities_per_image': ['No faces identified',\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.1183326244354248,\n",
       "      'norm': 20.043491,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.079074740409851,\n",
       "      'norm': 20.160065,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.2738022804260254,\n",
       "      'norm': 20.300863,\n",
       "      'quality': 'bad'}],\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.5742504596710205,\n",
       "      'norm': 20.100382,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4090754985809326,\n",
       "      'norm': 22.852654,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.563873529434204,\n",
       "      'norm': 20.154657,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.3331527709960938,\n",
       "      'norm': 20.609955,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.288572907447815,\n",
       "      'norm': 22.014908,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4128155708312988,\n",
       "      'norm': 22.85139,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4900104999542236,\n",
       "      'norm': 19.277626,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.5211749076843262,\n",
       "      'norm': 20.687908,\n",
       "      'quality': 'bad'}]]},\n",
       "  {'identities_per_image': ['No faces identified',\n",
       "    'No faces identified',\n",
       "    'No faces identified',\n",
       "    'No faces identified',\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.3235020637512207,\n",
       "      'norm': 21.301373,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 0.973495364189148,\n",
       "      'norm': 20.42754,\n",
       "      'quality': 'good'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4151850938796997,\n",
       "      'norm': 24.368881,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4289056062698364,\n",
       "      'norm': 22.458805,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.3728734254837036,\n",
       "      'norm': 20.680506,\n",
       "      'quality': 'bad'}]]},\n",
       "  {'identities_per_image': [[{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4307422637939453,\n",
       "      'norm': 19.022402,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.1652555465698242,\n",
       "      'norm': 20.390352,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4521681070327759,\n",
       "      'norm': 20.014463,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4674056768417358,\n",
       "      'norm': 23.278801,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4273126125335693,\n",
       "      'norm': 22.97988,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4621847867965698,\n",
       "      'norm': 19.39264,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4528963565826416,\n",
       "      'norm': 20.320442,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4135586023330688,\n",
       "      'norm': 21.371403,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4069504737854004,\n",
       "      'norm': 26.17408,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.3978346586227417,\n",
       "      'norm': 22.736874,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4945034980773926,\n",
       "      'norm': 21.009161,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.5031405687332153,\n",
       "      'norm': 21.573988,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4997063875198364,\n",
       "      'norm': 20.649954,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4740042686462402,\n",
       "      'norm': 20.096794,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.6070263385772705,\n",
       "      'norm': 19.891592,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.2050079107284546,\n",
       "      'norm': 21.371822,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 0.9650479555130005,\n",
       "      'norm': 21.86954,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.3521531820297241,\n",
       "      'norm': 19.398252,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4816112518310547,\n",
       "      'norm': 21.02183,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4868957996368408,\n",
       "      'norm': 22.80095,\n",
       "      'quality': 'bad'}]]},\n",
       "  {'identities_per_image': ['No faces identified',\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4915599822998047,\n",
       "      'norm': 22.4375,\n",
       "      'quality': 'bad'}],\n",
       "    'No faces identified',\n",
       "    'No faces identified',\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.460316777229309,\n",
       "      'norm': 19.15813,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4867854118347168,\n",
       "      'norm': 19.46227,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.5139617919921875,\n",
       "      'norm': 19.077024,\n",
       "      'quality': 'bad'}]]},\n",
       "  {'identities_per_image': ['No faces identified',\n",
       "    [{'person_id': 'Ke Huy Quan',\n",
       "      'image_id': 'f86a4eaa-5839-4a34-bb09-37782cdec90e',\n",
       "      'distance': 0.9990537166595459,\n",
       "      'norm': 20.251925,\n",
       "      'quality': 'good'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.3897937536239624,\n",
       "      'norm': 19.332685,\n",
       "      'quality': 'bad'}],\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.435909390449524,\n",
       "      'norm': 19.921358,\n",
       "      'quality': 'bad'}],\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4248714447021484,\n",
       "      'norm': 20.063143,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.5111969709396362,\n",
       "      'norm': 20.489838,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4262988567352295,\n",
       "      'norm': 20.097767,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.2817165851593018,\n",
       "      'norm': 19.422855,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4487202167510986,\n",
       "      'norm': 21.461021,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.1947323083877563,\n",
       "      'norm': 19.055824,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4763752222061157,\n",
       "      'norm': 22.486025,\n",
       "      'quality': 'bad'}],\n",
       "    'No faces identified']},\n",
       "  {'identities_per_image': [[{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4466313123703003,\n",
       "      'norm': 20.258425,\n",
       "      'quality': 'bad'}],\n",
       "    'No faces identified',\n",
       "    'No faces identified',\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.365605115890503,\n",
       "      'norm': 19.145634,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Ke Huy Quan',\n",
       "      'image_id': 'f86a4eaa-5839-4a34-bb09-37782cdec90e',\n",
       "      'distance': 0.7904183268547058,\n",
       "      'norm': 22.634085,\n",
       "      'quality': 'good'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4872794151306152,\n",
       "      'norm': 19.219349,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.501819372177124,\n",
       "      'norm': 24.446333,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.3953475952148438,\n",
       "      'norm': 20.004684,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4303570985794067,\n",
       "      'norm': 19.87882,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.5225698947906494,\n",
       "      'norm': 21.000006,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Ke Huy Quan',\n",
       "      'image_id': 'f86a4eaa-5839-4a34-bb09-37782cdec90e',\n",
       "      'distance': 0.9940075874328613,\n",
       "      'norm': 21.072355,\n",
       "      'quality': 'good'}]]},\n",
       "  {'identities_per_image': [[{'person_id': 'Narayana Cabral',\n",
       "      'image_id': '2b7f6412-cdf7-493c-85cb-3cbbe0692a38',\n",
       "      'distance': 1.167436957359314,\n",
       "      'norm': 20.66044,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'Narayana Cabral',\n",
       "      'image_id': '2b7f6412-cdf7-493c-85cb-3cbbe0692a38',\n",
       "      'distance': 1.1665332317352295,\n",
       "      'norm': 22.13147,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.1845507621765137,\n",
       "      'norm': 19.414785,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.3784213066101074,\n",
       "      'norm': 21.99937,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.2050851583480835,\n",
       "      'norm': 19.797348,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.453356146812439,\n",
       "      'norm': 19.976444,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.3714230060577393,\n",
       "      'norm': 19.606733,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.0401805639266968,\n",
       "      'norm': 22.295742,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.2538909912109375,\n",
       "      'norm': 20.40803,\n",
       "      'quality': 'bad'}]]},\n",
       "  {'identities_per_image': [[{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4359936714172363,\n",
       "      'norm': 21.65576,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.0892192125320435,\n",
       "      'norm': 19.9199,\n",
       "      'quality': 'good'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.5115524530410767,\n",
       "      'norm': 23.116104,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4467192888259888,\n",
       "      'norm': 19.068476,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4367889165878296,\n",
       "      'norm': 20.849009,\n",
       "      'quality': 'bad'}],\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'Ke Huy Quan',\n",
       "      'image_id': 'f86a4eaa-5839-4a34-bb09-37782cdec90e',\n",
       "      'distance': 0.9139755964279175,\n",
       "      'norm': 20.485638,\n",
       "      'quality': 'good'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.5613341331481934,\n",
       "      'norm': 20.17893,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.3309320211410522,\n",
       "      'norm': 20.621923,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4936892986297607,\n",
       "      'norm': 20.052395,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.173492431640625,\n",
       "      'norm': 20.849083,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.332571029663086,\n",
       "      'norm': 20.097404,\n",
       "      'quality': 'bad'}]]},\n",
       "  {'identities_per_image': ['No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4678452014923096,\n",
       "      'norm': 20.207554,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.0371177196502686,\n",
       "      'norm': 22.256678,\n",
       "      'quality': 'good'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4502474069595337,\n",
       "      'norm': 21.003212,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.1037815809249878,\n",
       "      'norm': 22.799067,\n",
       "      'quality': 'good'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4011099338531494,\n",
       "      'norm': 19.787167,\n",
       "      'quality': 'bad'}],\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.2266912460327148,\n",
       "      'norm': 20.536364,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Ke Huy Quan',\n",
       "      'image_id': 'f86a4eaa-5839-4a34-bb09-37782cdec90e',\n",
       "      'distance': 0.7631462812423706,\n",
       "      'norm': 20.576696,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 0.8538850545883179,\n",
       "      'norm': 21.362381,\n",
       "      'quality': 'good'}]]},\n",
       "  {'identities_per_image': [[{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.3652403354644775,\n",
       "      'norm': 20.965366,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.487443447113037,\n",
       "      'norm': 20.434923,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.5162973403930664,\n",
       "      'norm': 19.33938,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4919086694717407,\n",
       "      'norm': 21.796932,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4978480339050293,\n",
       "      'norm': 22.865234,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.379497766494751,\n",
       "      'norm': 23.533686,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4327245950698853,\n",
       "      'norm': 21.232355,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'James Hong',\n",
       "      'image_id': 'de9c8e31-524e-4667-8c25-5f33dfb992d0',\n",
       "      'distance': 0.8936232328414917,\n",
       "      'norm': 23.171516,\n",
       "      'quality': 'good'}],\n",
       "    'No faces identified',\n",
       "    'No faces identified',\n",
       "    'No faces identified']},\n",
       "  {'identities_per_image': [[{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.1941909790039062,\n",
       "      'norm': 19.623468,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.3409852981567383,\n",
       "      'norm': 21.209333,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4949650764465332,\n",
       "      'norm': 20.649736,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Ke Huy Quan',\n",
       "      'image_id': 'f86a4eaa-5839-4a34-bb09-37782cdec90e',\n",
       "      'distance': 0.8139544129371643,\n",
       "      'norm': 20.863497,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'Ke Huy Quan',\n",
       "      'image_id': 'f86a4eaa-5839-4a34-bb09-37782cdec90e',\n",
       "      'distance': 1.1371486186981201,\n",
       "      'norm': 19.227507,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.380812168121338,\n",
       "      'norm': 19.566637,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.100914716720581,\n",
       "      'norm': 23.124977,\n",
       "      'quality': 'good'}],\n",
       "    'No faces identified',\n",
       "    'No faces identified']},\n",
       "  {'identities_per_image': ['No faces identified',\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 0.8939871191978455,\n",
       "      'norm': 20.238203,\n",
       "      'quality': 'good'}],\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.0680431127548218,\n",
       "      'norm': 19.960133,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.452057957649231,\n",
       "      'norm': 21.012531,\n",
       "      'quality': 'bad'},\n",
       "     {'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.0591373443603516,\n",
       "      'norm': 21.216904,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.2395853996276855,\n",
       "      'norm': 22.544025,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.111539602279663,\n",
       "      'norm': 19.598867,\n",
       "      'quality': 'good'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.390230655670166,\n",
       "      'norm': 20.477013,\n",
       "      'quality': 'bad'}]]},\n",
       "  {'identities_per_image': [[{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4254634380340576,\n",
       "      'norm': 21.349697,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.0947548151016235,\n",
       "      'norm': 21.325161,\n",
       "      'quality': 'good'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.3629298210144043,\n",
       "      'norm': 20.926859,\n",
       "      'quality': 'bad'}],\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.2365801334381104,\n",
       "      'norm': 20.603048,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.181246042251587,\n",
       "      'norm': 21.22729,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 0.993235170841217,\n",
       "      'norm': 19.190632,\n",
       "      'quality': 'good'}],\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.0042469501495361,\n",
       "      'norm': 21.479805,\n",
       "      'quality': 'good'}]]},\n",
       "  {'identities_per_image': [[{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.0282658338546753,\n",
       "      'norm': 19.618639,\n",
       "      'quality': 'good'}],\n",
       "    'No faces identified',\n",
       "    'No faces identified',\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.054842472076416,\n",
       "      'norm': 21.451279,\n",
       "      'quality': 'good'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.47145676612854,\n",
       "      'norm': 20.807722,\n",
       "      'quality': 'bad'}],\n",
       "    [{'person_id': 'Michelle Yeoh',\n",
       "      'image_id': '85c0155f-8783-4b3d-b837-21f7490a6ea1',\n",
       "      'distance': 1.1034184694290161,\n",
       "      'norm': 20.642412,\n",
       "      'quality': 'good'},\n",
       "     {'person_id': 'unknown',\n",
       "      'image_id': 'unknown',\n",
       "      'distance': 1.4593091011047363,\n",
       "      'norm': 23.621508,\n",
       "      'quality': 'bad'}],\n",
       "    'No faces identified',\n",
       "    'No faces identified']}],\n",
       " 'timestamps': [0.0,\n",
       "  3.003000020980835,\n",
       "  3.6700000762939453,\n",
       "  6.25600004196167,\n",
       "  6.631999969482422,\n",
       "  8.550999641418457,\n",
       "  10.928000450134277,\n",
       "  12.512999534606934,\n",
       "  14.013999938964844,\n",
       "  14.973999977111816,\n",
       "  16.808000564575195,\n",
       "  17.350000381469727,\n",
       "  17.93400001525879,\n",
       "  18.60099983215332,\n",
       "  19.768999099731445,\n",
       "  20.854000091552734,\n",
       "  21.479000091552734,\n",
       "  21.89699935913086,\n",
       "  22.731000900268555,\n",
       "  23.690000534057617,\n",
       "  24.482999801635742,\n",
       "  25.775999069213867,\n",
       "  26.985000610351562,\n",
       "  27.986000061035156,\n",
       "  29.11199951171875,\n",
       "  31.11400032043457,\n",
       "  31.947999954223633,\n",
       "  33.03300094604492,\n",
       "  38.45500183105469,\n",
       "  38.49700164794922,\n",
       "  42.54199981689453,\n",
       "  44.12699890136719,\n",
       "  45.16999816894531,\n",
       "  46.42100143432617,\n",
       "  49.04899978637695,\n",
       "  52.051998138427734,\n",
       "  53.095001220703125,\n",
       "  53.92900085449219,\n",
       "  54.76300048828125,\n",
       "  54.93000030517578,\n",
       "  55.18000030517578,\n",
       "  55.43000030517578,\n",
       "  55.638999938964844,\n",
       "  57.93299865722656,\n",
       "  58.599998474121094,\n",
       "  59.058998107910156,\n",
       "  60.518001556396484,\n",
       "  61.22800064086914,\n",
       "  62.0620002746582,\n",
       "  62.3120002746582,\n",
       "  63.14699935913086,\n",
       "  65.44000244140625,\n",
       "  66.10700225830078,\n",
       "  67.0250015258789,\n",
       "  67.9010009765625,\n",
       "  69.0270004272461,\n",
       "  70.23600006103516,\n",
       "  70.52799987792969,\n",
       "  71.02899932861328,\n",
       "  71.15399932861328,\n",
       "  71.6969985961914,\n",
       "  72.697998046875,\n",
       "  73.74099731445312,\n",
       "  74.53299713134766,\n",
       "  75.20099639892578,\n",
       "  75.70099639892578,\n",
       "  77.0770034790039,\n",
       "  78.87100219726562,\n",
       "  79.28800201416016,\n",
       "  80.83100128173828,\n",
       "  82.04000091552734,\n",
       "  82.58200073242188,\n",
       "  83.54199981689453,\n",
       "  84.16699981689453,\n",
       "  84.95999908447266,\n",
       "  86.46099853515625,\n",
       "  86.75299835205078,\n",
       "  87.46199798583984,\n",
       "  87.83699798583984,\n",
       "  88.62999725341797,\n",
       "  89.75599670410156,\n",
       "  92.21700286865234,\n",
       "  93.302001953125,\n",
       "  94.01100158691406,\n",
       "  94.84500122070312,\n",
       "  98.8489990234375,\n",
       "  99.0989990234375,\n",
       "  99.9749984741211,\n",
       "  102.97799682617188,\n",
       "  104.56300354003906,\n",
       "  106.77400207519531,\n",
       "  108.73400115966797,\n",
       "  109.7770004272461,\n",
       "  110.6520004272461,\n",
       "  111.11100006103516,\n",
       "  111.90299987792969,\n",
       "  112.65399932861328,\n",
       "  113.27999877929688,\n",
       "  113.98899841308594,\n",
       "  114.947998046875,\n",
       "  115.8239974975586,\n",
       "  116.61699676513672,\n",
       "  117.24199676513672,\n",
       "  117.32599639892578,\n",
       "  117.40899658203125,\n",
       "  117.90899658203125,\n",
       "  118.9520034790039,\n",
       "  119.8280029296875,\n",
       "  120.66200256347656,\n",
       "  121.66300201416016,\n",
       "  122.49700164794922,\n",
       "  124.54100036621094,\n",
       "  125.66699981689453,\n",
       "  128.08599853515625,\n",
       "  129.04600524902344,\n",
       "  131.13099670410156,\n",
       "  132.3820037841797,\n",
       "  133.3000030517578,\n",
       "  134.00900268554688,\n",
       "  135.177001953125,\n",
       "  135.968994140625,\n",
       "  136.97000122070312,\n",
       "  137.6790008544922,\n",
       "  138.13800048828125,\n",
       "  138.5970001220703,\n",
       "  139.63900756835938,\n",
       "  140.38999938964844,\n",
       "  141.14100646972656,\n",
       "  141.30799865722656,\n",
       "  142.01699829101562,\n",
       "  142.5590057373047,\n",
       "  143.05999755859375,\n",
       "  143.43499755859375,\n",
       "  143.8520050048828,\n",
       "  144.1439971923828,\n",
       "  144.85299682617188,\n",
       "  144.97799682617188,\n",
       "  149.4409942626953,\n",
       "  150.31700134277344,\n",
       "  150.44200134277344,\n",
       "  150.56700134277344,\n",
       "  150.69200134277344,\n",
       "  150.7760009765625,\n",
       "  150.85899353027344,\n",
       "  150.9429931640625,\n",
       "  151.0679931640625,\n",
       "  151.1929931640625,\n",
       "  151.4010009765625,\n",
       "  151.48500061035156,\n",
       "  151.5679931640625,\n",
       "  151.6929931640625,\n",
       "  151.8179931640625,\n",
       "  152.02699279785156,\n",
       "  152.23500061035156,\n",
       "  152.48599243164062,\n",
       "  152.6529998779297,\n",
       "  152.81900024414062,\n",
       "  153.0279998779297,\n",
       "  153.9040069580078],\n",
       " 'frame_ids': [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6],\n",
       " 'video_duration': 161.536375}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m extract_face_feats_batched(\u001b[43mimage_paths\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_paths' is not defined"
     ]
    }
   ],
   "source": [
    "res = extract_face_feats_batched(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mres\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 28/33541 [00:07<2:38:11,  3.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/nas/dominic/AanaFaceEval/identities_reference/default/*.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_filepath \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(image_paths):\n\u001b[0;32m---> 17\u001b[0m     face_feats, norms \u001b[38;5;241m=\u001b[39m \u001b[43mextract_face_feats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_filepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#import pdb; pdb.set_trace()\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(face_feats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(face_feats)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m norms[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m19.0\u001b[39m):\n",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m, in \u001b[0;36mextract_face_feats\u001b[0;34m(im_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_face_feats\u001b[39m(im_path):\n\u001b[1;32m      6\u001b[0m     data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      8\u001b[0m         {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m: im_path}\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m     ],\n\u001b[1;32m     11\u001b[0m     }\n\u001b[0;32m---> 13\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://127.0.0.1:8000/recognize_faces\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     res \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface_features_per_image\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface_feats\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface_features_per_image\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorms\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aana-vIr3-B0u-py3.10/lib/python3.10/site-packages/urllib3/connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/usr/local/python/3.10.14/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/python/3.10.14/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.10.14/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/python/3.10.14/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "reference_faces_dict_30K_webface4M_r101 = {\n",
    "    \"person_names\": [],\n",
    "    \"paths_to_image\": [],\n",
    "    \"face_features\": [],\n",
    "    \"norms\": [],\n",
    "}\n",
    "\n",
    "failed_faces = []\n",
    "\n",
    "image_paths = sorted(\n",
    "    glob.glob(\"/nas/dominic/AanaFaceEval/identities_reference/default/*.jpg\")\n",
    ")\n",
    "\n",
    "for image_filepath in tqdm.tqdm(image_paths):\n",
    "    face_feats, norms = extract_face_feats(image_filepath)\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "    if face_feats is not None and len(face_feats) == 1 and norms[0][0] >= 19.0:\n",
    "        reference_faces_dict_30K_webface4M_r101[\"person_names\"].append(\n",
    "            os.path.basename(image_filepath)[0:-4].split(\"|||\")[-1]\n",
    "        )\n",
    "        reference_faces_dict_30K_webface4M_r101[\"paths_to_image\"].append(image_filepath)\n",
    "        reference_faces_dict_30K_webface4M_r101[\"face_features\"].append(face_feats[0])\n",
    "        reference_faces_dict_30K_webface4M_r101[\"norms\"].append(norms[0][0])\n",
    "    else:\n",
    "        failed_faces.append([image_filepath, norms[0][0]])\n",
    "\n",
    "reverse_reference_faces_dict_30K_webface4M_r101 = {\n",
    "    reference_faces_dict_30K_webface4M_r101[\"person_names\"][\n",
    "        k\n",
    "    ]: reference_faces_dict_30K_webface4M_r101[\"paths_to_image\"][k]\n",
    "    for k in range(len(reference_faces_dict_30K_webface4M_r101[\"person_names\"]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aana-vIr3-B0u-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
